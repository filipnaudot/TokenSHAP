{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a986e77-a33d-4b9a-8e87-281743194af8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from token_shap import TokenSHAP\n",
    "from nltk.corpus import words\n",
    "from termcolor import colored\n",
    "import random\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4de0ae5-8b41-49c4-97a2-71b6e01f789f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e242163-8d32-4ff2-a2b0-79a32fd4c323",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def inject_random_words(prompts, injection_rate=(0.2, 0.3)):\n",
    "    word_list = words.words()\n",
    "    injected_prompts = []\n",
    "    dict_injected = {}\n",
    "    for prompt in prompts:\n",
    "        words_in_prompt = prompt.split()\n",
    "        num_injections = int(len(words_in_prompt) * random.uniform(*injection_rate))\n",
    "        injection_indices = random.sample(range(len(words_in_prompt) + 1), num_injections)\n",
    "        random_words = []\n",
    "        for index in sorted(injection_indices, reverse=True):\n",
    "            random_word = random.choice(word_list)\n",
    "            words_in_prompt.insert(index, random_word)\n",
    "            random_words.append(random_word)\n",
    "        injected_prompts.append(' '.join(words_in_prompt))\n",
    "        dict_injected[prompt] = random_words\n",
    "    return injected_prompts, dict_injected\n",
    "\n",
    "def color_injected_words(original_prompts, injected_prompts, n):\n",
    "    for _ in range(n):\n",
    "        idx = random.randint(0, len(original_prompts) - 1)\n",
    "        original_words = set(original_prompts[idx].split())\n",
    "        injected_words = injected_prompts[idx].split()\n",
    "        \n",
    "        colored_prompt = []\n",
    "        for word in injected_words:\n",
    "            if word not in original_words:\n",
    "                colored_prompt.append(colored(word, 'red'))\n",
    "            else:\n",
    "                colored_prompt.append(word)\n",
    "        \n",
    "        print(' '.join(colored_prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1984902a-b364-4778-9265-552323edad96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds = load_dataset(\"tatsu-lab/alpaca\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd5a93b-8edc-4b35-83f4-5360ce7d79b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompts = random.sample(ds['train']['instruction'], 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07be018-e3f2-4799-9bbd-418a2547f21c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "injected_prompts, dict_injected = inject_random_words(prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86b9043-8330-4752-a6db-fb0fda6a66fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "color_injected_words(prompts, injected_prompts, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f22153-0033-447a-9256-bed66d4f65dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Initialize TokenSHAP with your model & tokenizer\n",
    "model_name = \"llama3\"\n",
    "tshap = TokenSHAP(model_name, tokenizer_path = \"NousResearch/Hermes-2-Theta-Llama-3-8B\")\n",
    "original_shap_values = {}\n",
    "for prompt in prompts:\n",
    "    results = tshap.analyze(prompt, sampling_ratio = 0.2, splitter = ' ')\n",
    "    original_shap_values[prompt] = tshap.shapley_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73273a2-b97f-4ee6-9def-689af75ea22c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Initialize TokenSHAP with your model & tokenizer\n",
    "model_name = \"llama3\"\n",
    "tshap = TokenSHAP(model_name, tokenizer_path = \"NousResearch/Hermes-2-Theta-Llama-3-8B\")\n",
    "injected_shap_values = {}\n",
    "for prompt in injected_prompts:\n",
    "    results = tshap.analyze(prompt, sampling_ratio = 0.2, splitter = ' ')\n",
    "    injected_shap_values[prompt] = tshap.shapley_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a76bd27-51d9-4eae-a7b5-e43a598c3eb5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "all_words = defaultdict(list)\n",
    "for prompt_dict in original_shap_values.values():\n",
    "    for word, value in prompt_dict.items():\n",
    "        all_words[word].append(value)\n",
    "for prompt_dict in injected_shap_values.values():\n",
    "    for word, value in prompt_dict.items():\n",
    "        all_words[word].append(value)\n",
    "\n",
    "word_shap =  {word: np.mean(values) for word, values in all_words.items()}\n",
    "word_shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b455ff-fbc5-4398-8672-77b9121b09f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "word_freq = defaultdict(int)\n",
    "for prompt in prompts + injected_prompts:\n",
    "    for word in prompt.split():\n",
    "        word_freq[word] += 1\n",
    "\n",
    "injected_words = set([word for words in dict_injected.values() for word in words])\n",
    "word_correlation = {}\n",
    "for word in word_shap.keys():\n",
    "    in_injected = sum(1 for prompt in injected_prompts if word in prompt.split())\n",
    "    in_original = sum(1 for prompt in prompts if word in prompt.split())\n",
    "    word_correlation[word] = (in_injected / len(injected_prompts)) - (in_original / len(prompts))\n",
    "\n",
    "results = pd.DataFrame({\n",
    "    'word': list(word_shap.keys()),\n",
    "    'shap_value': list(word_shap.values()),\n",
    "    'correlation': [word_correlation.get(word, 0) for word in word_shap.keys()],\n",
    "    'frequency': [word_freq.get(word, 0) for word in word_shap.keys()],\n",
    "    'is_injected': [word in injected_words for word in word_shap.keys()]\n",
    "})\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b023538-2fc5-4e2c-bbcd-ba5e83bfc320",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "low_importance_words = set(results[results['shap_value'] < low_importance_threshold]['word'])\n",
    "injected_words = set([word for words in dict_injected.values() for word in words])\n",
    "\n",
    "low_importance_injected = low_importance_words.intersection(injected_words)\n",
    "print(f\"Number of low importance words that are also injected: {len(low_importance_injected)}\")\n",
    "print(f\"Percentage of injected words that are low importance: {len(low_importance_injected) / len(injected_words) * 100:.2f}%\")\n",
    "\n",
    "correlation_matrix = np.corrcoef(results['shap_value'], results['is_injected'])\n",
    "print(f\"Correlation coefficient between SHAP values and being an injected word: {correlation_matrix[0, 1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80b9d8f-0137-4ed9-b00f-fcff4cdccf5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "low_importance_threshold=0.1\n",
    "low_importance_words = results[results['shap_value'] < low_importance_threshold]\n",
    "    \n",
    "plt.figure(figsize=(12, 8))\n",
    "scatter = plt.scatter(low_importance_words['shap_value'], \n",
    "                      low_importance_words['correlation'],\n",
    "                      c=low_importance_words['frequency'], \n",
    "                      cmap='viridis', \n",
    "                      s=low_importance_words['frequency'], \n",
    "                      alpha=0.6)\n",
    "plt.colorbar(scatter, label='Frequency')\n",
    "plt.xlabel('SHAP Value')\n",
    "plt.ylabel('Correlation with Injected Words')\n",
    "plt.title('Low Importance Words: SHAP Value vs. Correlation with Injected Words')\n",
    "\n",
    "for _, row in low_importance_words.nlargest(10, 'correlation').iterrows():\n",
    "    plt.annotate(row['word'], (row['shap_value'], row['correlation']))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "heatmap_data = top_low_importance[['shap_value', 'correlation', 'frequency']].astype(float)\n",
    "heatmap_data['is_injected'] = top_low_importance['is_injected'].astype(int)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(heatmap_data.set_index(top_low_importance['word']), \n",
    "            annot=True, cmap='YlOrRd', fmt='.2f')\n",
    "plt.title('Top 20 Low Importance Words by Correlation with Injected Words')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_env",
   "language": "python",
   "name": "llm_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
