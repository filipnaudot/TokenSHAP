{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a986e77-a33d-4b9a-8e87-281743194af8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from token_shap import TokenSHAP\n",
    "from nltk.corpus import words\n",
    "from termcolor import colored\n",
    "import random\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4de0ae5-8b41-49c4-97a2-71b6e01f789f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to /home/miriam/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb59745-565e-4614-b75e-7ad3fab20386",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Get Aplaca Sample and Inject Random Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e242163-8d32-4ff2-a2b0-79a32fd4c323",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def inject_random_words(prompts, injection_rate=(0.2, 0.3)):\n",
    "    word_list = words.words()\n",
    "    injected_prompts = []\n",
    "    dict_injected = {}\n",
    "    for prompt in prompts:\n",
    "        words_in_prompt = prompt.split()\n",
    "        num_injections = int(len(words_in_prompt) * random.uniform(*injection_rate))\n",
    "        injection_indices = random.sample(range(len(words_in_prompt) + 1), num_injections)\n",
    "        random_words = []\n",
    "        for index in sorted(injection_indices, reverse=True):\n",
    "            random_word = random.choice(word_list)\n",
    "            words_in_prompt.insert(index, random_word)\n",
    "            random_words.append(random_word)\n",
    "        injected_prompts.append(' '.join(words_in_prompt))\n",
    "        dict_injected[prompt] = random_words\n",
    "    return injected_prompts, dict_injected\n",
    "\n",
    "def color_injected_words(original_prompts, injected_prompts, n):\n",
    "    for _ in range(n):\n",
    "        idx = random.randint(0, len(original_prompts) - 1)\n",
    "        original_words = set(original_prompts[idx].split())\n",
    "        injected_words = injected_prompts[idx].split()\n",
    "\n",
    "        colored_prompt = []\n",
    "        for word in injected_words:\n",
    "            if word not in original_words:\n",
    "                colored_prompt.append(colored(word, 'red'))\n",
    "            else:\n",
    "                colored_prompt.append(word)\n",
    "\n",
    "        print(' '.join(colored_prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1984902a-b364-4778-9265-552323edad96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds = load_dataset(\"tatsu-lab/alpaca\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd5a93b-8edc-4b35-83f4-5360ce7d79b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompts = ds['train']['instruction'][55:75]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f07be018-e3f2-4799-9bbd-418a2547f21c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "injected_prompts, dict_injected = inject_random_words(prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d86b9043-8330-4752-a6db-fb0fda6a66fe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mcantharidism\u001b[0m What is \u001b[31mwickawee\u001b[0m the \u001b[31mnonextenuatory\u001b[0m force on a 1 kg mass due to the gravitational force?\n",
      "Construct \u001b[31munbragged\u001b[0m an argument to defend the following statement\n",
      "Provide \u001b[31mstruvite\u001b[0m one example for a cultural practice.\n",
      "What \u001b[31mkarstic\u001b[0m type of plant is a skunk cabbage? \u001b[31mkibitz\u001b[0m\n",
      "\u001b[31meight\u001b[0m Transform the following sentence into the passive voice \u001b[31mmowrah\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "color_injected_words(prompts, injected_prompts, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b7191046-253a-4aa7-b7f1-13780b7ef7cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cantharidism What is wickawee the nonextenuatory force on a 1 kg mass due to the gravitational force?',\n",
       " 'Provide struvite one example for a cultural practice.',\n",
       " 'Given a chromophile set of numbers, find the maximum tuillette value.',\n",
       " 'Give two examples of a slanderousness liquid.',\n",
       " 'What is the product Dardic of 6 and 2?',\n",
       " 'What karstic type of plant is a skunk cabbage? kibitz',\n",
       " 'Convert the given binary gladioli number to its extraschool decimal equivalent.',\n",
       " 'Name unrubrical two types of desert biomes.',\n",
       " 'Given a sentence, convert it into otomucormycosis passive voice.',\n",
       " 'eight Transform the following sentence into the passive voice mowrah',\n",
       " 'Create a dialog between two people afterhours who are disgarland discussing a scientific phenomenon',\n",
       " 'Identify duodena the most suitable adverb Coos for the following sentence',\n",
       " 'Find the main idea of the following filiform passage',\n",
       " 'Analyze the tone reverberation of the following sentences',\n",
       " 'Construct unbragged an argument to defend the following statement',\n",
       " 'Convert the following sentence into jonglery the present methylenitan continuous tense',\n",
       " 'Give methodic an example of grihyasutra a metaphor that uses the following object',\n",
       " 'Describe the following person',\n",
       " 'Construct nonthinker a mathematical problem with the following numbers',\n",
       " 'Aim to reduce the following scolopophore sentence without changing its meaning Trogoniformes']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "injected_prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f911f2db-636a-4964-84e5-7d19bc6f2784",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Token SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f22153-0033-447a-9256-bed66d4f65dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# Initialize TokenSHAP with your model & tokenizer\n",
    "model_name = \"llama3\"\n",
    "tokenizer_path = \"NousResearch/Hermes-2-Theta-Llama-3-8B\"\n",
    "ollama_api_url = \"http://localhost:11434\"  # Default Ollama API URL\n",
    "tshap = TokenSHAP(model_name, tokenizer_path, ollama_api_url)\n",
    "\n",
    "# Path to save SHAP values\n",
    "save_path = \"shap_values.json\"\n",
    "\n",
    "# Load existing SHAP values if the file exists\n",
    "if os.path.exists(save_path):\n",
    "    with open(save_path, 'r') as f:\n",
    "        original_shap_values = json.load(f)\n",
    "else:\n",
    "    original_shap_values = {}\n",
    "\n",
    "# Function to save SHAP values to disk\n",
    "def save_shap_values(shap_values, save_path):\n",
    "    with open(save_path, 'w') as f:\n",
    "        json.dump(shap_values, f)\n",
    "\n",
    "for prompt in prompts:\n",
    "    results = tshap.analyze(prompt, sampling_ratio=0, splitter=' ')\n",
    "    original_shap_values[prompt] = tshap.shapley_values\n",
    "    save_shap_values(original_shap_values, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73273a2-b97f-4ee6-9def-689af75ea22c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Initialize TokenSHAP with your model & tokenizer\n",
    "model_name = \"llama3\"\n",
    "tokenizer_path = \"NousResearch/Hermes-2-Theta-Llama-3-8B\"\n",
    "ollama_api_url = \"http://localhost:11434\"  # Default Ollama API URL\n",
    "tshap = TokenSHAP(model_name, tokenizer_path, ollama_api_url)\n",
    "\n",
    "# Path to save SHAP values\n",
    "save_path = \"injected_shap_values.json\"\n",
    "\n",
    "# Load existing SHAP values if the file exists\n",
    "if os.path.exists(save_path):\n",
    "    with open(save_path, 'r') as f:\n",
    "        injected_shap_values = json.load(f)\n",
    "else:\n",
    "    injected_shap_values = {}\n",
    "\n",
    "for prompt in injected_prompts:\n",
    "    results = tshap.analyze(prompt, sampling_ratio = 0, splitter = ' ')\n",
    "    injected_shap_values[prompt] = tshap.shapley_values\n",
    "    save_shap_values(injected_shap_values, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a76bd27-51d9-4eae-a7b5-e43a598c3eb5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "all_words = defaultdict(list)\n",
    "for prompt_dict in original_shap_values.values():\n",
    "    for word, value in prompt_dict.items():\n",
    "        all_words[word].append(value)\n",
    "for prompt_dict in injected_shap_values.values():\n",
    "    for word, value in prompt_dict.items():\n",
    "        all_words[word].append(value)\n",
    "\n",
    "word_shap =  {word: np.mean(values) for word, values in all_words.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "90b455ff-fbc5-4398-8672-77b9121b09f1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>shap_value</th>\n",
       "      <th>correlation</th>\n",
       "      <th>frequency</th>\n",
       "      <th>is_injected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What_1</td>\n",
       "      <td>0.071385</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is_2</td>\n",
       "      <td>0.010272</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the_3</td>\n",
       "      <td>0.010391</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>force_4</td>\n",
       "      <td>0.118616</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>on_5</td>\n",
       "      <td>0.075602</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>without_8</td>\n",
       "      <td>0.076004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>changing_9</td>\n",
       "      <td>0.046533</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>its_10</td>\n",
       "      <td>0.081086</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>meaning_11</td>\n",
       "      <td>0.128880</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>Trogoniformes_12</td>\n",
       "      <td>0.091815</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>246 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 word  shap_value  correlation  frequency  is_injected\n",
       "0              What_1    0.071385          0.0          0        False\n",
       "1                is_2    0.010272          0.0          0        False\n",
       "2               the_3    0.010391          0.0          0        False\n",
       "3             force_4    0.118616          0.0          0        False\n",
       "4                on_5    0.075602          0.0          0        False\n",
       "..                ...         ...          ...        ...          ...\n",
       "241         without_8    0.076004          0.0          0        False\n",
       "242        changing_9    0.046533          0.0          0        False\n",
       "243            its_10    0.081086          0.0          0        False\n",
       "244        meaning_11    0.128880          0.0          0        False\n",
       "245  Trogoniformes_12    0.091815          0.0          0         True\n",
       "\n",
       "[246 rows x 5 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "word_freq = defaultdict(int)\n",
    "for prompt in prompts + injected_prompts:\n",
    "    for word in prompt.split():\n",
    "        word_freq[word] += 1\n",
    "\n",
    "injected_words = set([word for words in dict_injected.values() for word in words])\n",
    "word_correlation = {}\n",
    "for word in word_shap.keys():\n",
    "    in_injected = sum(1 for prompt in injected_prompts if word in prompt.split())\n",
    "    in_original = sum(1 for prompt in prompts if word in prompt.split())\n",
    "    word_correlation[word] = (in_injected / len(injected_prompts)) - (in_original / len(prompts))\n",
    "\n",
    "results = pd.DataFrame({\n",
    "    'word': list(word_shap.keys()),\n",
    "    'shap_value': list(word_shap.values()),\n",
    "    'correlation': [word_correlation.get(word, 0) for word in word_shap.keys()],\n",
    "    'frequency': [word_freq.get(word, 0) for word in word_shap.keys()],\n",
    "    'is_injected': [word.split('_')[0] in injected_words for word in word_shap.keys()]\n",
    "})\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8b4e9376-14f9-49bb-92f1-c221b9a8fe0b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average SHAP value for injected words: 0.0789\n",
      "Average SHAP value for non-injected words: 0.1127\n",
      "Average SHAP value diff for non-injected words compared to injected words: 0.0338\n",
      "Std SHAP value for injected words: 0.0641\n",
      "Std SHAP value for non-injected words: 0.0757\n",
      "Std SHAP value diff for non-injected words compared to injected words: 0.0116\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "word_freq = defaultdict(int)\n",
    "for prompt in prompts + injected_prompts:\n",
    "    for word in prompt.split():\n",
    "        word_freq[word] += 1\n",
    "\n",
    "injected_words = set([word for words in dict_injected.values() for word in words])\n",
    "word_correlation = {}\n",
    "for word in word_shap.keys():\n",
    "    in_injected = sum(1 for prompt in injected_prompts if word in prompt.split())\n",
    "    in_original = sum(1 for prompt in prompts if word in prompt.split())\n",
    "    word_correlation[word] = (in_injected / len(injected_prompts)) - (in_original / len(prompts))\n",
    "\n",
    "results = pd.DataFrame({\n",
    "    'word': list(word_shap.keys()),\n",
    "    'shap_value': list(word_shap.values()),\n",
    "    'correlation': [word_correlation.get(word, 0) for word in word_shap.keys()],\n",
    "    'frequency': [word_freq.get(word, 0) for word in word_shap.keys()],\n",
    "    'is_injected': [word.split('_')[0] in injected_words for word in word_shap.keys()]\n",
    "})\n",
    "\n",
    "\n",
    "\n",
    "# Assuming your data is in a pandas DataFrame called 'df'\n",
    "df = results\n",
    "# 1. Box plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='is_injected', y='shap_value', data=df)\n",
    "plt.title('Distribution of SHAP Values for Injected and Non-Injected Words')\n",
    "plt.xlabel('Is Injected')\n",
    "plt.ylabel('SHAP Value')\n",
    "plt.savefig('boxplot_shap_injection.png')\n",
    "plt.close()\n",
    "\n",
    "\n",
    "# Calculate and print average SHAP values\n",
    "avg_shap_injected = df[df['is_injected'] == True]['shap_value'].mean()\n",
    "avg_shap_non_injected = df[df['is_injected'] == False]['shap_value'].mean()\n",
    "std_shap_injected = df[df['is_injected'] == True]['shap_value'].std()\n",
    "std_shap_non_injected = df[df['is_injected'] == False]['shap_value'].std()\n",
    "print(f\"Average SHAP value for injected words: {avg_shap_injected:.4f}\")\n",
    "print(f\"Average SHAP value for non-injected words: {avg_shap_non_injected:.4f}\")\n",
    "print(f\"Average SHAP value diff for non-injected words compared to injected words: {avg_shap_non_injected - avg_shap_injected:.4f}\")\n",
    "print(f\"Std SHAP value for injected words: {std_shap_injected:.4f}\")\n",
    "print(f\"Std SHAP value for non-injected words: {std_shap_non_injected:.4f}\")\n",
    "print(f\"Std SHAP value diff for non-injected words compared to injected words: {std_shap_non_injected - std_shap_injected:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe3c270-38e3-4420-aed9-486b88bb9d04",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Random Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f2e579-d2d1-478a-b86f-1b69ab918f89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from baseline import *\n",
    "\n",
    "baseline = NaiveBaseline(\"llama3\", \"NousResearch/Hermes-2-Theta-Llama-3-8B\")\n",
    "\n",
    "# Path to save SHAP values\n",
    "save_path = \"shap_values_baseline_random.json\"\n",
    "\n",
    "# Load existing SHAP values if the file exists\n",
    "if os.path.exists(save_path):\n",
    "    with open(save_path, 'r') as f:\n",
    "        original_shap_values = json.load(f)\n",
    "else:\n",
    "    original_shap_values = {}\n",
    "\n",
    "\n",
    "for prompt in prompts:\n",
    "    print(prompt)\n",
    "    results = baseline.analyze_and_plot(prompt, method='random')\n",
    "    print(results)\n",
    "    original_shap_values[prompt] = results\n",
    "    save_shap_values(original_shap_values, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7a7949-9a00-48df-89ed-01db110742f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Path to save SHAP values\n",
    "save_path = \"injected_shap_values_baseline_random.json\"\n",
    "\n",
    "# Load existing SHAP values if the file exists\n",
    "if os.path.exists(save_path):\n",
    "    with open(save_path, 'r') as f:\n",
    "        injected_shap_values = json.load(f)\n",
    "else:\n",
    "    injected_shap_values = {}\n",
    "\n",
    "for prompt in injected_prompts:\n",
    "    print(prompt)\n",
    "    results = baseline.analyze_and_plot(prompt, method='random')\n",
    "    injected_shap_values[prompt] = results\n",
    "    save_shap_values(injected_shap_values, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "b9f1fc03-68c3-493a-aee8-9c6d60451897",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average SHAP value for injected words: 0.0974\n",
      "Average SHAP value for non-injected words: 0.1144\n",
      "Average SHAP value diff for non-injected words compared to injected words: 0.0171\n",
      "Std SHAP value for injected words: 0.0706\n",
      "Std SHAP value for non-injected words: 0.0537\n",
      "Std SHAP value diff for non-injected words compared to injected words: -0.0169\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "all_words = defaultdict(list)\n",
    "for prompt_dict in original_shap_values.values():\n",
    "    for word, value in prompt_dict.items():\n",
    "        all_words[word].append(value)\n",
    "for prompt_dict in injected_shap_values.values():\n",
    "    for word, value in prompt_dict.items():\n",
    "        all_words[word].append(value)\n",
    "\n",
    "word_shap =  {word: np.mean(values) for word, values in all_words.items()}\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "word_freq = defaultdict(int)\n",
    "for prompt in prompts + injected_prompts:\n",
    "    for word in prompt.split():\n",
    "        word_freq[word] += 1\n",
    "\n",
    "injected_words = set([word for words in dict_injected.values() for word in words])\n",
    "word_correlation = {}\n",
    "for word in word_shap.keys():\n",
    "    in_injected = sum(1 for prompt in injected_prompts if word in prompt.split())\n",
    "    in_original = sum(1 for prompt in prompts if word in prompt.split())\n",
    "    word_correlation[word] = (in_injected / len(injected_prompts)) - (in_original / len(prompts))\n",
    "\n",
    "results = pd.DataFrame({\n",
    "    'word': list(word_shap.keys()),\n",
    "    'shap_value': list(word_shap.values()),\n",
    "    'correlation': [word_correlation.get(word, 0) for word in word_shap.keys()],\n",
    "    'frequency': [word_freq.get(word, 0) for word in word_shap.keys()],\n",
    "    'is_injected': [word.split('_')[0] in injected_words for word in word_shap.keys()]\n",
    "})\n",
    "\n",
    "\n",
    "\n",
    "# Assuming your data is in a pandas DataFrame called 'df'\n",
    "df = results\n",
    "# 1. Box plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='is_injected', y='shap_value', data=df)\n",
    "plt.title('Distribution of SHAP Values for Injected and Non-Injected Words')\n",
    "plt.xlabel('Is Injected')\n",
    "plt.ylabel('SHAP Value')\n",
    "plt.savefig('boxplot_shap_injection_baseline_random.png')\n",
    "plt.close()\n",
    "\n",
    "\n",
    "# Calculate and print average SHAP values\n",
    "avg_shap_injected = df[df['is_injected'] == True]['shap_value'].mean()\n",
    "avg_shap_non_injected = df[df['is_injected'] == False]['shap_value'].mean()\n",
    "std_shap_injected = df[df['is_injected'] == True]['shap_value'].std()\n",
    "std_shap_non_injected = df[df['is_injected'] == False]['shap_value'].std()\n",
    "print(f\"Average SHAP value for injected words: {avg_shap_injected:.4f}\")\n",
    "print(f\"Average SHAP value for non-injected words: {avg_shap_non_injected:.4f}\")\n",
    "print(f\"Average SHAP value diff for non-injected words compared to injected words: {avg_shap_non_injected - avg_shap_injected:.4f}\")\n",
    "print(f\"Std SHAP value for injected words: {std_shap_injected:.4f}\")\n",
    "print(f\"Std SHAP value for non-injected words: {std_shap_non_injected:.4f}\")\n",
    "print(f\"Std SHAP value diff for non-injected words compared to injected words: {std_shap_non_injected - std_shap_injected:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627d424f-3bdf-436d-9bf6-542572c93207",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Prompt Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2e3c98-4731-4ff0-8695-7d5763dfb50d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "import importlib\n",
    "import prompt_engineering\n",
    "\n",
    "# Reload the baseline module\n",
    "importlib.reload(prompt_engineering)\n",
    "\n",
    "# Now you can use the reloaded module\n",
    "from prompt_engineering import *\n",
    "\n",
    "\n",
    "from prompt_engineering import *\n",
    "engineer = PromptEngineer(\"llama3\")\n",
    "\n",
    "\n",
    "# Path to save SHAP values\n",
    "save_path = \"shap_values_prompt_engineer.json\"\n",
    "\n",
    "# Load existing SHAP values if the file exists\n",
    "if os.path.exists(save_path):\n",
    "    with open(save_path, 'r') as f:\n",
    "        original_shap_values = json.load(f)\n",
    "else:\n",
    "    original_shap_values = {}\n",
    "\n",
    "\n",
    "for prompt in prompts:\n",
    "    results = engineer.analyze_and_plot(prompt)\n",
    "    original_shap_values[prompt] = results\n",
    "    save_shap_values(original_shap_values, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa8bf07-b6c5-4786-9c0c-f98a624c4d3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Path to save SHAP values\n",
    "save_path = \"injected_shap_values_prompt_engineer.json\"\n",
    "\n",
    "# Load existing SHAP values if the file exists\n",
    "if os.path.exists(save_path):\n",
    "    with open(save_path, 'r') as f:\n",
    "        injected_shap_values = json.load(f)\n",
    "else:\n",
    "    injected_shap_values = {}\n",
    "\n",
    "for prompt in injected_prompts:\n",
    "    results = engineer.analyze_and_plot(prompt)\n",
    "    injected_shap_values[prompt] = results\n",
    "    save_shap_values(injected_shap_values, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "087ced4f-5eff-40d9-b557-deab4bf91655",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average SHAP value for injected words: 0.1069\n",
      "Average SHAP value for non-injected words: 0.1254\n",
      "Average SHAP value diff for non-injected words compared to injected words: 0.0185\n",
      "Std SHAP value for injected words: 0.0819\n",
      "Std SHAP value for non-injected words: 0.0723\n",
      "Std SHAP value diff for non-injected words compared to injected words: -0.0096\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "all_words = defaultdict(list)\n",
    "for prompt_dict in original_shap_values.values():\n",
    "    if prompt_dict is None:\n",
    "        continue\n",
    "    for word, value in prompt_dict.items():\n",
    "        all_words[word].append(value)\n",
    "for prompt_dict in injected_shap_values.values():\n",
    "    if prompt_dict is None:\n",
    "        continue\n",
    "    for word, value in prompt_dict.items():\n",
    "        all_words[word].append(value)\n",
    "\n",
    "word_shap =  {word: np.mean(values) for word, values in all_words.items()}\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "word_freq = defaultdict(int)\n",
    "for prompt in prompts + injected_prompts:\n",
    "    for word in prompt.split():\n",
    "        word_freq[word] += 1\n",
    "\n",
    "injected_words = set([word for words in dict_injected.values() for word in words])\n",
    "word_correlation = {}\n",
    "for word in word_shap.keys():\n",
    "    in_injected = sum(1 for prompt in injected_prompts if word in prompt.split())\n",
    "    in_original = sum(1 for prompt in prompts if word in prompt.split())\n",
    "    word_correlation[word] = (in_injected / len(injected_prompts)) - (in_original / len(prompts))\n",
    "\n",
    "results = pd.DataFrame({\n",
    "    'word': list(word_shap.keys()),\n",
    "    'shap_value': list(word_shap.values()),\n",
    "    'correlation': [word_correlation.get(word, 0) for word in word_shap.keys()],\n",
    "    'frequency': [word_freq.get(word, 0) for word in word_shap.keys()],\n",
    "    'is_injected': [word.split('_')[0] in injected_words for word in word_shap.keys()]\n",
    "})\n",
    "\n",
    "\n",
    "\n",
    "# Assuming your data is in a pandas DataFrame called 'df'\n",
    "df = results\n",
    "# 1. Box plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='is_injected', y='shap_value', data=df)\n",
    "plt.title('Distribution of SHAP Values for Injected and Non-Injected Words')\n",
    "plt.xlabel('Is Injected')\n",
    "plt.ylabel('SHAP Value')\n",
    "plt.savefig('boxplot_shap_injection_propmpt_engineer.png')\n",
    "plt.close()\n",
    "\n",
    "\n",
    "# Calculate and print average SHAP values\n",
    "avg_shap_injected = df[df['is_injected'] == True]['shap_value'].mean()\n",
    "avg_shap_non_injected = df[df['is_injected'] == False]['shap_value'].mean()\n",
    "std_shap_injected = df[df['is_injected'] == True]['shap_value'].std()\n",
    "std_shap_non_injected = df[df['is_injected'] == False]['shap_value'].std()\n",
    "print(f\"Average SHAP value for injected words: {avg_shap_injected:.4f}\")\n",
    "print(f\"Average SHAP value for non-injected words: {avg_shap_non_injected:.4f}\")\n",
    "print(f\"Average SHAP value diff for non-injected words compared to injected words: {avg_shap_non_injected - avg_shap_injected:.4f}\")\n",
    "print(f\"Std SHAP value for injected words: {std_shap_injected:.4f}\")\n",
    "print(f\"Std SHAP value for non-injected words: {std_shap_non_injected:.4f}\")\n",
    "print(f\"Std SHAP value diff for non-injected words compared to injected words: {std_shap_non_injected - std_shap_injected:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_env",
   "language": "python",
   "name": "llm_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
